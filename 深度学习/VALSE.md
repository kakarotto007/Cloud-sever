# 	面向视觉的零样本学习

## 报告题目: 基于生成模型的零样本视觉识别

>  报告嘉宾: 李晶晶(电子科技大学)

监督学习的限制：标签输出

One-on-One: bad generation ,   Generative Learning: 学习样本的特征分布

语义到空间的映射面临的挑战：

<img src="https://raw.githubusercontent.com/kakarotto007/final/master/image-20231025201250169.png" alt="image-20231025201250169" style="zoom: 67%;" />

<img src="https://raw.githubusercontent.com/kakarotto007/final/master/image-20231025204124682.png" alt="image-20231025204124682" style="zoom:50%;" />



## 报告题目: Prompting-The New API for Interactive Visual Intelligence

>  报告嘉宾: 周锴阳(港浸会大学)

提示学习应用于Few-Shot learning，在数据分布偏移的数据集上也有性能上的提升，学到的提示overfitting

Visual in-context learning

<img src="https://raw.githubusercontent.com/kakarotto007/final/master/image-20231025210543115.png" alt="image-20231025210543115" style="zoom: 50%;" />



## Panel议题:

1，经典的零样本学习方法和基于大规模视觉-语言模型的零样本学习方法(例如CLIP)的具有各自优劣势，未来方向可否同时兼顾两种方法的优势? 未来面向视觉的零样本学习的路在何方?

经典的：学习语义空间，因为依赖于手工设计的语义，泛化性较弱。 

2，LLM具有很强的推理和丰富的知识，LLM能否推进面向视觉的零样本学习? 有哪些潜在的研究价值和方向?

对新的class生成好的描述，生成多个描述。

3，当前零样本学习仍是极具挑战性的研究课题，离工业落地具有一定的距离。当前是否有必要结合实际的业界应用场景推进零样本学习研究?

4，当前大模型的涌现，学术界应该如何面对工业界靠数据、计算资源取胜的局面? 除了靠数据和计算资源，还有什么可以推进一个领域的发展?
