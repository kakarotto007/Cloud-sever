

# 模板

## 《CLAP: Learning Audio Concepts From Natural Language Supervision》

### 0 Abstract

---

## 1 Introduction

---

## 2 Method

---

## 3 Experiment

---

## 4 Result and Discussion

---

## 5 Conclusion



# DOA

## 《Adaptation of Multiple Sound Source Localization Neural Networks with Weak Supervision and Domain-adversarial Training》

深度学习的声源定位方法有两个主要缺点

1. 标记数据获取带有注释的真实数据是一项艰巨的任务。
2. 它们对训练和测试条件之间的不匹配的敏感性。

## 《A SURVEY OF SOUND SOURCE LOCALIZATION WITH DEEPLEARNING METHODS》

> 尽管多年来它们在该领域的显着进步，但它们在噪声、混响和几个同时发射声源可能存在的困难但常见的场景中表现不佳

Although they have shown notable advances in the domain over the years, they are known to perform poorly in difficult yet common scenarios where noise, reverberation, and several simultaneously emitting sound sources may be present.

> 基于深度学习的声源定位系统比传统的声源定位方法好

Most of the reported works have indicated the superiority of DNN-based SSL methods over conventional (i.e., SP-based) SSL methods. 

> General pipeline of a DL-based SSL system.

![image-20231010144807698](https://raw.githubusercontent.com/kakarotto007/final/master/image-20231010144807698.png)

---

**Acoustic environments**

1. 回响
2. 噪声（记录设备的缺陷可能是另一个噪声源）

**Source types**

1. speech（用于 语音增强和语音识别）
2. DCASE上的数据集（虽然他们有时候overlap，但是不一定困难，这是因为他们的频谱特征有明显的差别）

---

**Conventional SSL methods reasons** 

1. 传统的SSL方法经常被用作基于DL的方法的基线；

2. 许多基于DL的SSL方法使用用传统方法提取的输入特征。

**Conventional SSL methods** 

1. GCC-PHAT
2. SRP-PHAT
3. 基于子空间的方法（MUSIC、ESPRIT）
4. ICA

---

**Neural network architectures for SSL**

> Feedforward neural networks（前馈神经网络）（MLP）

复值的mlp比实值的mlp要好

输入特征是IThe interaural time difference (ITD) and the interaural level difference (ILD) 和GCC-PHAT

可以把它当作分类或者是回归问题

4层隐藏层的MLP与4层cnn有相似的结果

==针对不对频率子带（协方差矩阵的特征向量的频率）设计了不同的MLP，每个MLP有8层隐藏层。这是假设每个频率子带有一个声源主导的。全连接层之后是输出，输出是与频率相关的==

弱监督的MLP，因为损失函数没有用到ground truth DOA 标签

---

> Convolutional neural networks

M个麦克风，利用麦克风的相位相关性最好的卷积层数是M-1

网络的末端被分成两个卷积分支，一个用于方位估计，另一个用于语音/非语音信号分类。

也可以把多通道的原始音频当作输入。

mask估计doa，对TF图做mask。A method based on mask estimation was proposed by Zhang et al. [2019b], in which a TF mask was estimated and used to either clean or be appended to the input features, facilitating the DoA estimation by a CNN.

利用单个源训练出的系统就可以对多声源进行定位：. Fahim et al. [2020] applied an 8-layer CNN to the so-called modal coherence of first-order Ambisonics input features (see Section 5) for the localization of multiple sources in a reverberant environment. They proposed a new method to train a multi-source DoA estimation network with only single-source training data, showing an improvement over the system of Chakrabarty and Habets [2019b], especially for signals with three speakers. 

深度可分离卷积有更高的准确率以及更小的模型复杂度。

Bologni等人[2021]提出了一种神经网络架构，包括一组用于逐帧特征提取的2D卷积层，然后是用于时间聚合的时间维度上的几个1D卷积层。《Acoustic Reflectors Localization from Stereo Recordings Using Neural Networks》

输入特征是SPR-PHAT

空洞卷积会减少计算量并且会使最佳的cnn层数减小。

---

> Recurrent neural networks

TF掩码来增强信号

---

> Convolutional recurrent neural networks

两个阶段的神经网络，已经验证通过生成spatial pseudo-spectrum的中间输出对声源定位有帮助。

加入高斯噪声可以让神经网络更加鲁棒。

数据增强和后处理。

通过加入更多卷积层，并且减少max-pooling可以减少层传递之间的信息损失。

把传统卷积替换为GLU后，可以更好的提取相位相关的特征。

加入TCN后考虑到了时间上下文信息，就可以提升定位准确率。

---

> Residual neural networks

> Attention–based neural networks

加入attention之后更能提取时间相关的信息

cross-modal attention(CMA)models,  cross-attention

> Encoder-decoder neural networks

**Autoencoder:**

对抗训练，从仿真环境下训练到真实环境：《Data-efficient framework for real-world multiple sound source 2D localization》，他们引入了一种新的显式变换层，帮助网络对麦克风阵列布局保持不变。训练鉴别器网络将传入的数据标记为合成或真实，并学习欺骗鉴别器的生成器网络。这使得 DoA 估计网络的适应能够从真实数据中推断出。

seld的输入是原始音频：《SoundDet: Polyphonic Moving Sound Event Detection and Localization from Raw Waveform》

一个encoder对应着两个deconders：《SSLIDE: sound source localization for indoors based on deep learning》第二个分支的decoder可以让网络更加的鲁棒。

encoder-decoder输出GCC的TDOA，表现比经典的TDOA好。

**Variational autoencoder**

VAR通常应用于无监督学习，VAE可以看作是AE的概率版本，与经典AE不同，VAE学习解码器输出端数据的概率分布，并对瓶颈层所谓潜在向量的概率分布进行建模，这使得VAE与无监督表示学习的概念紧密相连，因此，解码器可以通过对这些分布进行采样来获得新的数据。

《Semi-Supervised Source Localization in Reverberant Environments With Deep Generative Modeling》他们的VAE由卷积层组成，经过训练以生成麦克风间RTF的相位（见第5.1.1节），通过RTF相位估计说过者的DOA。这里用无标签的RTF和有标签的数据进行半监督学习。

**U-Net architecture**

一开始在图像分割中被提出来，在U-net中，输入特征在整个编码器层被分解为连续的特征图，然后在整个解码器层被重新组合为“对称”特征图，类似于CNN。在编码器和解码器中具有相同级别的特征图的相同维度使得能够经由残差连接将信息从编码器级别直接传播到解码器的相应级别。这导致了典型的U形示意图。残差连接用于将一个编码器输出连接到同一阶段解码器的输入，以缓解损失信息问题。

《Dynamically locating multiple speakers based on the time-frequency domain》多移动声源

《The cone of silence: speech separation by localization》输入是原始音频

《DCASE2020TASK3:ASINGLESTAGEFULLYCONVOLUTIONALNEURALNETWORK FORSOUNDSOURCELOCALIZATIONANDDETECTION》输入是log-mel+gcc-phat  输出是doa和sed

TASLP：《Source Localization Using Distributed Microphones in Reverberant Environments Based on Deep Learning and Ray Space Transform》，第一阶段用来生成GCC-PHAT，第二阶段采用U-net

### Input features

所考虑的特征可以是低级信号表示，例如波形或频谱图、手工制作的特征，例如双耳特征，或者 MUSIC 或 GCC-PHAT。

### Output strategies

分类和回归，也可以用神经网络估计中间变量，然后用传统的声源定位算法估计doa。

### Data augmentation techniques

《A Four-Stage Data Augmentation Approach to ResNet-Conformer Based Acoustic Modeling for Sound Event Localization and Detection》

1. changing the location of the sources by swapping audio channels.
2. The second method is based on the extraction of spatial and spectral information on the sources, which are then modified and recombined to create new training exampless
3. The third one relies on mixing multiple examples, resulting in new multi-source labelled mixtures. 
4. The fourth technique is based on random TF masking.

### Learning strategies

该网络使用标记数据训练进行预训练，并使用无监督学习进行细化(或微调)。在SSL中已经提出了半监督学习来提高神经网络在监督训练或真实数据看不见的条件下的性能，与仅在监督方式训练时的性能相比。这可以看作是丰富尺寸或条件过有限标记训练数据集的替代方法。

### Conclusions and perspectives

#### Adaptation to (limited sets of) real-world data







# Audio-Visual 

## 《Visual Sound Localization in the Wild by Cross-Modal Interference Erasing》-AAAI

#### Abstract

屏幕外的声音以及背景噪声会影响定位，key idea是通过重新定义和雕刻有区别的音频表示来消除干扰，通过跨模态蒸馏的跨模态参考器模块来擦除  可以听到的屏幕外的声音以及静默但可见物体的影响。

#### 1 Introduction

《Multiple Sound Sources Localization from Coarse to Fine》：从粗粒度到细粒度解决问题，但是依赖于音频类的标签

《Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching》在干净的声场环境下，两阶段的策略，抑制不发声声源的影响。

Motivation：多声源造成的挑战：1）在定位任务中，模型只趋向于去定位声音大的声源，需要更多的音频表示。2）看不见的声源以及背景噪声会对视听定位造成影响。

在paper中，提出了一个无标签的方法叫做Interference Eraser。

contributions：1）设计了一个Audio-Instance-Identifier来擦除声音幅值在不均匀音频混合中对判别音频感知的影响。2）设计了跨模态参考模块来消除干扰

#### 2 Related Work

> Audio-Visual Correspondence Learning

音频和视频之间的对应关系为多模态场景下的学习提供了自然和丰富的自我监督。

其他论文：1）生成视听相关图 — 计算每个空间网格的全局音频嵌入以及视觉特征的相似度。2）采用试听一致性来对齐通道跨模态分布。

前面提到的都是针对一个声源的情况。

> Visual Sound Source Localization

看不懂了

# SELD

## 《ZERO- AND FEW-SHOT SOUND EVENT LOCALIZATION AND DETECTION》

### Abstract

已知可以使用 contrastive language-audio pretraining（CLAP）生成声音时间类别以及对应的标签，但是对于SELD任务还需要对给音频分配给相应的DOA

motivation：为了解决DOA的分配问题

contributions：提出了一种embedd-ACCODA模型，该模型被训练为输出按轨迹的CLAP嵌入和相关的ACCDOA。

### Introduction

零样本分类问题可以通过计算CLAP的音频query和文本的embeddings的cosin相似度来实现。

![image-20231019103848404](https://raw.githubusercontent.com/kakarotto007/final/master/image-20231019103848404.png)

text：输入为 $X_{t}^{c}$，c是class，通过text encoder –> D维的$E_{c}^{t}$

audio; 输入为$X_{}^{q'}$，通过audio encoder -> D维的$E_{}^{q'}$。 然后对两个D维的向量做余弦相似度。

与零样本的SED任务不同，零样本的SELD任务需要输出每个时间帧，去考虑重叠的声音事件以及相关联的DOAembeddings。



## 《Exploring Self-Supervised Contrastive Learning of Spatial Sound Event Representation》

### 0 Abstract

同时学习 spectral（光谱的）和 spatial （空间的）的特征。

提出了multi-level数据增强pipeline：waveforms，Mel spectrograms， GCC特征。

此外还提出了一种通道随机swap，它是simple and effective的，防止为了在特定通道的过拟合。

通过使用数据增强，他们发现线性层比有监督的学习效果要好。

### 1 Introduction

**缺少音频信息的注释**使得大规模有监督训练不能实现，所以提出了第一个多通道的自监督表示方法， a simple multi-channel framework for contrastive learning (MC-SimCLR) 是 a simple framework for contrastive learning的 adaptation.

---

### 2 Related Works

自监督学习不需要明确的标签，是一种很有前途的表征学习方法。学习到的表示通常用作下游任务的输入特征，减少了对大量标记训练数据的需求，并且提高了任务性能。

#### 	2.1 SED领域

- Bade on SimCLR，通过对比学习最大化相同片段的相似度，最小化不同片段的相似度
- Self-distrllation 方法自蒸馏方法通过让在线编码器预测目标编码器的嵌入，在不对比多个片段的情况下实现了相同的目标。
- 此外，transformer补丁建模方法还通过代理任务从未掩蔽的频谱图补丁中预测和重建掩蔽的谱图补丁来学习事件分类的判别特征。

#### 	2.2 DOA领域

《Sound Localization by Self-Supervised Time Delay Estimation》通过对比学习，但是对声源数量有限制。

---

### 3 MC-SIMCLR

为了有效地从未标记的多通道音频中捕捉这种相似性，MC-SimCLR提取光谱和空间特征，对各种特征和维度进行增强，并在训练过程中优化对比目标。

#### 	3.1 Input Features

**提取waveforms：**We crop two random patches, denoted as ${x_i},{x_j}\in{\mathbb{R} }_{}^{M\times N} $ , 形成一对正样本。 一段waveform是M channels和持续一秒的音频。不够一秒的用 0 paded ， 两个patch可能有重叠。

**提取Mel和GCC特征**: ${X}^{MEL}\in \mathbb{R}^{M\times F \times T}$  ，${X}^{GCC}\in \mathbb{R}^{M/2\times F \times T}$

<img src="https://raw.githubusercontent.com/kakarotto007/final/master/image-20231023155753078.png" alt="image-20231023155753078" style="zoom:80%;" />

最后拼接特征在通道维度上，一共十个channels：4个Mel spectrograms 和 6个GCC features

#### 	3.2 Multi-level Data Augmentation

以前单通道的data augmentation： Mixup、 RandomResizeCrop 、 SpecAugment 、 Compression 都是主要在Mel 图上的。

本次pipeline：

1. we apply **Mixup** to multi-channel **waveforms instead of Mel spectrograms** and RandomResizeCrop concurrently **on all channels of both Mel and GCC features.**
2. Furthermore, we introduce novel channelwise data augmentation methods **ChannelSwap**, which operates on the order of the microphones, and **ChannelDrop**, which randomly **masks** Mel and GCC channels.

我们描述了应用于输入数据的序列中的每种数据增强方法，**从波形开始，在到达编码器之前通过Mel和GCC特征进行。**以类似的方式集成额外的数据扩充具有灵活性。

#### 	3.3 ChannelSwap

重新排列圆形或四面体麦克风阵列中波形的麦克风顺序，从而产生新的记录，在改变空间位置的同时保持频谱特性，而不需要额外的记录或模拟。

如果是4通道的圆形麦克风阵列，对应着8钟通道重排：翻转（-1和1）和旋转（0.90.-90.180），在有监督的训练模式下可以产生八倍多的音频。

但是在我们的情况下，尽管我们不知道ChannelSwap之前或之后的方位值，但我们注意到，ChannelSwap之前方向相似的两个样本（即正对）在操作之后应该继续表现出相似的方向。因此，我们对一个话语的两个片段应用具有相同但随机排列的ChannelSwap，以生成更多对正样本。

#### 	3.4 Mixup

mix一个目标源x和另外一个随机源y，通过convex结合：

<img src="https://raw.githubusercontent.com/kakarotto007/final/master/image-20231023161607146.png" alt="image-20231023161607146" style="zoom:80%;" />

以前都是混合Mel谱图，现在我们混合了多通道波形图，来融合谱图和空间信息同时。值得注意的是，我们在确保目标源的突出度之前和之后执行波形归一化，以抵消任何统计偏移。α一般这是为【0，0.01】

#### 	3.5 RandomResizedCrop

RandomResizedCrop对输入图像执行大小调整和裁剪。在空间音频的背景下，Mel和GCC特征都可以被视为2D图像。RandomResizedCropon在Mel特征上的应用引起了（pitch shifting and time stretching effects.）音高偏移和时间拉伸效应。在GCC特征的情况下，除了时间拉伸之外，它还会在源方向上引起轻微的扰动。这种战略调整有助于生成以紧密相邻的方向为特征的正对，而无需精确了解这些来源的确切位置。

剪裁比例设置为：【0.8，1】、纵横比设置为【0.8，1.25】

#### 	3.6 ChannelDrop

于Mel和GCC通道，我们以小概率p将整个通道随机屏蔽为全零。我们观察到，在没有对所有感兴趣的任务进行强有力的监督的情况下，**该模型倾向于关注单个通道或一小部分通道，**从而导致下游任务的次优解决方案。ChannelDrop通过删除整个频道有效地解决了这种潜在的频道偏见，迫使模型关注所有频道以及Mel和GCC功能。（加入关心a通道，把a通道删除，就增加泛化性）

概率设置为p=0.1

#### 	3.8 Projection Head and Contrastive Loss

正样本对${x_i},{x_j}$，通过特征提取、数据增强、encoder后得到${h_i},{h_j}$ 。然后通过 two-layer perceptron把${h_i},{h_j}$投影到${z_i},{z_j}$.

对比损失定义为如下：

<img src="https://raw.githubusercontent.com/kakarotto007/final/master/image-20231023163139809.png" alt="image-20231023163139809" style="zoom:80%;" />

sim是余弦相似度，投影仪P被丢弃用于监督评估，hi和hj是提取的空间嵌入。

---

### 4 Experiment

#### 	4.1 Data Simulation

数据集：FSDnoisy18k dataset  with gpuRIR toolbox。

**FSDnoisy18**k：包括包括单声道音频源，每个音频源属于20个不同类别中的一个，例如引擎、足迹和吉他。

**房间：**对于每个源，我们模拟了一个房间，其宽度、长度和高度从[3.0,10.0]、[3.0,1.0]和[2.5,4.0]米的范围内均匀采样，混响时间（RT60）从[0.1,1.0]秒均匀采样。

**麦克风阵列：**我们还模拟了一个直径为0.1米的圆形全向麦克风阵列，配备了4个均匀间隔的麦克风。源和阵列被放置在房间内的随机位置，其高度以[0.5,2.0]米为单位选择。为了确保正确放置，它们与房间墙壁和彼此之间的距离至少为0.5米。

**FSDnoisy18k**：包含一个较大的噪声（noisy）训练集（15813个片段/38.8小时）、一个较小的干净（clean）训练集（1772个片段/2.4小时）和一个测试（testing）集（947个片段/1.4小时）。为了验证（validation）目的，从clean中随机选择了200个剪辑。每个实验包括两个步骤：对噪声（noisy）的自我监督预训练（第4.2节）和对干净（clean）的监督评估（第4.3节）。我们报告了模型在测试集（testing）上的性能。

#### 	4.2 Model and Pre-training

encode用的是CRNN，embeddding dimension是128.batch size 是512

我们对编码器进行了500个时期的训练，在前10个时期以线性学习率预热开始，在剩余时期以余弦学习率衰减[30]为0。所有实验均在NVIDIA L40 GPU上进行

#### 	4.3 Supervised Evaluation

- Linear-probing：分别训练了两个线性层，分别用于事件分类和角度预测，encoder冻结。
- Fine-tuning：联合训练了两个线性层，并同时更新encoder。
- Subset Fine-tuning：与微调相同，但我们只使用标记数据的子集。

除了使用128的较小批量和0.01的学习率外，我们遵循与预训练步骤相同的超参数。**除了ChannelSwap之外**，没有使用任何数据扩充，因为它被证明可以提高监督SELD性能[9]。此外，如果微调预先训练的模型，我们将0.1的比例因子应用于编码器的梯度，以防止在clean上过拟合。

---

### 5 Result

<img src="https://raw.githubusercontent.com/kakarotto007/final/master/image-20231023170303551.png" alt="image-20231023170303551" style="zoom:80%;" />

灰色的是随机初始化的encoder。

### 6 Conclusion

本研究介绍了MC-SimCLR，一种专门用于多声道音频信号的对比学习框架。MC SimCLR熟练地利用未标记的空间音频记录来提取强大的组合频谱和空间表示。在训练过程中，通过跨越波形、Mel谱图和GCC特征的多层次多维数据增强流水线来增强这种表示。通过这些增强功能，与从头开始的训练相比，MC SimCLR在事件分类和本地化方面取得了显著改进。我**们未来的工作将致力于学习移动或重叠空间声音事件的表现**



# SED

## 《CLAP: Learning Audio Concepts From Natural Language Supervision》

### 0 Abstract



---

## 1 Introduction

---

## 2 Method

---

## 3 Experiment

---

## 4 Result and Discussion

---

## 5 Conclusion

